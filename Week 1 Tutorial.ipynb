{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eb26cb7",
   "metadata": {},
   "source": [
    "# Causal Data Science Week 1 Tutorial\n",
    "\n",
    "This is the first tutorial for the Causal Data Science course. In it, we will give an overview of the python libaries that are used in the course: numpy, pandas, and more. Familiarity with these libraries is necessary to apply the 'DoWhy' package - a library used in implementing causal analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160bdad2",
   "metadata": {},
   "source": [
    "## numpy\n",
    "\n",
    "numpy is a library used for storing data and performing numerical operations on it. The documentation is available at: https://numpy.org/doc/stable/index.html, which is where these examples are drawn from (here we show just some exampes of what we can do with numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da2e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first import numpy under the name 'np'\n",
    "import numpy as np\n",
    "\n",
    "# we convert the python list [6, 7, 8] into a numpy array name 'a'\n",
    "a = np.array([6, 7, 8])\n",
    "\n",
    "# we can view 'a' by calling it\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d1b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to provide a list to create a numpy array\n",
    "a = np.array(1, 2, 3, 4)    # WRONG, a list, [ ], needs to be provided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d235dcc9",
   "metadata": {},
   "source": [
    "numpy arrays can be multidimensional. Here, we used arange(15) to make the list [0, 1, 2, 3, 4, ..., 14], and turn it into a 3 x 5 matrix, and name it 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.arange(15).reshape(3, 5)\n",
    "\n",
    "# we can again view 'b'\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e9648b",
   "metadata": {},
   "source": [
    "We can perform operations on numpy arrays. Some of the key functions include things like addition, subtraction, exponentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create two numpy arrays, 'a' and 'b', and add them together\n",
    "a = np.array([20, 30, 40, 50])\n",
    "b = np.arange(4) # this is the array [0, 1, 2, 3]\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1616264",
   "metadata": {},
   "source": [
    "Arrays can be indexed and sliced the same way as lists in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1372eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we view the array 'a' from the first element (labelled 0) to the 2nd element\n",
    "a[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa0ade",
   "metadata": {},
   "source": [
    "With numpy and the other libraries we are using, you can usually find answers to any questions you have quite easily by googling/StackOverflow e.g. 'how to do integration numpy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4d5da7",
   "metadata": {},
   "source": [
    "## pandas\n",
    "\n",
    "pandas are used to store and manipulate dataframes, with multiple columns measuring different attributes. They are used as inputs for many machine learning libraries, including the library used in this course: DoWhy. Information and examples are available at https://pandas.pydata.org/pandas-docs/stable/index.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325dfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first import pandas under the name 'pd'\n",
    "import pandas as pd\n",
    "\n",
    "# we create a dataframe name 'df'. The letters 'A', 'B', 'C', etc. represent the columns and the rest the values for that column\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": 1.0,\n",
    "        \"B\": pd.Timestamp(\"20130102\"),\n",
    "        \"C\": pd.Series(1, index=list(range(4)), dtype=\"float32\"),\n",
    "        \"D\": np.array([3] * 4, dtype=\"int32\"),\n",
    "        \"E\": pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "        \"F\": \"foo\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# we can view our dataframe by calling it\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b94dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can view the first n rows of a dataframe using 'dataframe_name'.head(n)\n",
    "df.head(3) # first three rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019ce6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can view column(s) from the dataframe by calling the desired column(s)\n",
    "df['E'] # column E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e52c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can view specific rows using indices\n",
    "df[0:2] # rows 0 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af24ddc",
   "metadata": {},
   "source": [
    "Data in a pandas dataframe can be plotted easily using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb484bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import pyplot with the name 'plt'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# we create a random pandas series and apply the cumsum function\n",
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range(\"1/1/2000\", periods=1000))\n",
    "\n",
    "ts = ts.cumsum()\n",
    "\n",
    "ts.plot() # this is the command that plots the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts # this is the data plotted above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we've created a pandas dataframe again using random data, now with fours different columns 'A', 'B', 'C', and 'D'\n",
    "df = pd.DataFrame(\n",
    "    np.random.randn(1000, 4), index=ts.index, columns=[\"A\", \"B\", \"C\", \"D\"]\n",
    ")\n",
    "\n",
    "# again we apply the cumsum function\n",
    "df = df.cumsum()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e2bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# we can again plot the data, only now different columns are plotted separately\n",
    "df.plot()\n",
    "\n",
    "plt.legend(loc='best') # each column is plotted as a separate line in the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59211cdd",
   "metadata": {},
   "source": [
    "Data can be read into and written from pandas dataframes using formats like csv and excel files  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8bf628",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"foo.csv\") # writing to a file called 'foo' with type csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0783d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"foo.csv\") # reading from a csv file called 'foo'\n",
    "\n",
    "# we can view the imported dataframe\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c3458c",
   "metadata": {},
   "source": [
    "As with numpy, most of your questions about pandas can be answered with some good googling!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd802e84",
   "metadata": {},
   "source": [
    "## scikit-learn\n",
    "\n",
    "scikit-learn is a library used for tackling machine learning problems. It implements a number of supervised and unsupervised learning algorithms. The documentation is available at https://scikit-learn.org/stable/, and these examples are taken from https://scikit-learn.org/stable/tutorial/basic/tutorial.html.\n",
    "\n",
    "Here, we import some example data from the library and fit a support vector machine (SVM) to classify what digits certain images show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca44956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import 'datasets' from sklearn and load the 'digits' data\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde8ba53",
   "metadata": {},
   "source": [
    "We have a features data set (digits.data) and a targets data set (digits.target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10156cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e0804",
   "metadata": {},
   "source": [
    "We can learn a model using 'fit', and then estimate targets based on unseen features using 'predict'. In this case, we use all data except the last sample to build the model, and then predict on the last. The model predicts that this last digit is '8'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad804bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# we create a svm.SVC object called 'clf'\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "\n",
    "# we fit the model using the 'digits' data, leaving out the last data point\n",
    "clf.fit(digits.data[:-1], digits.target[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7508df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now use our fitted model to predict the last data point\n",
    "clf.predict(digits.data[-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67468490",
   "metadata": {},
   "source": [
    "## DoWhy\n",
    "\n",
    "DoWhy (https://www.pywhy.org/dowhy/v0.9.1/) is a Python library designed for performing causal inference. This is one of the main libraries we will be using in this course. It allows one quickly to identify and test causal relationships based on data and a causal graph.\n",
    "\n",
    "You will first need to install the library using:\n",
    "pip install dowhy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c80bcb2",
   "metadata": {},
   "source": [
    "We will go through the example at https://www.pywhy.org/dowhy/v0.9.1/getting_started/index.html to get a basic overview of the library. It is not expected that you understand all steps of this process now, as this is what you will be learning through the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b87def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import the 'dowhy' library, the 'CausalModel' class, and 'dowhy.datasets' (this last for generated simulated data to test)\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import dowhy.datasets\n",
    "\n",
    "# the code below simple hides some warnings we don't want to see\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98a7a05",
   "metadata": {},
   "source": [
    "We use a data generator from DoWhy to create a simulated data set where 'beta' is the true causal effect. This data also has a causal graph associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca49afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dowhy.datasets.linear_dataset(beta=10,\n",
    "        num_common_causes=5,\n",
    "        num_instruments = 2,\n",
    "        num_samples=10000,\n",
    "        treatment_is_binary=True)\n",
    "\n",
    "# we extract the generated dataframe, and name it 'df'\n",
    "df = data[\"df\"]\n",
    "\n",
    "# we can view the first few entries in the dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106aa2c8",
   "metadata": {},
   "source": [
    "There is also a causal graph for this data, and we can view it in two different formats: 'dot graph' and 'gml graph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791be532",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"dot_graph\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"gml_graph\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179c56f",
   "metadata": {},
   "source": [
    "We create a causal model with the data, the treatment variable, the outcome variable, and the causal graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8db624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With graph\n",
    "model=CausalModel(\n",
    "        data = df,\n",
    "        treatment=data[\"treatment_name\"],\n",
    "        outcome=data[\"outcome_name\"],\n",
    "        graph=data[\"gml_graph\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b835489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can visualise the model/graph\n",
    "model.view_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92e59a",
   "metadata": {},
   "source": [
    "Based on the graph, we can identify computable expressions based on the graph only. We can then evaluate these expressions in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6437e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_estimand = model.identify_effect()\n",
    "print(identified_estimand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803e4819",
   "metadata": {},
   "source": [
    "We can calculate a causal estimate based on the data and the expressions found in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ef502",
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_estimate = model.estimate_effect(identified_estimand,\n",
    "        method_name=\"backdoor.propensity_score_stratification\")\n",
    "print(causal_estimate)\n",
    "print(\"Causal Estimate is \" + str(causal_estimate.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1fe4b0",
   "metadata": {},
   "source": [
    "Finally, there are a number of techniques we can apply to test whether the estimate is accurate when adding in noise, downsampling, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fc297",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_random=model.refute_estimate(identified_estimand, causal_estimate, method_name=\"random_common_cause\")\n",
    "print(res_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe8f35",
   "metadata": {},
   "source": [
    "Here we've added a random common cause, and it has not significantly affected our estimate. This gives us more confidence in our estimate. There are numerous other refutation techniques available in DoWhy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac56b7",
   "metadata": {},
   "source": [
    "The example above uses synthetic data generated according to a causal graph. We can also apply DoWhy to real-world data where we believe there to be an underlying causal graph. In this example, we use DoWhy on the Infant Health and Development Program Dataset (Hill, J. L. (2011). Bayesian nonparametric modeling for causal inference. Journal of Computational and Graphical Statistics, 20(1), 217-240. https://doi.org/10.1198/jcgs.2010.08162). The example is taken from https://www.pywhy.org/dowhy/v0.9.1/example_notebooks/dowhy_refutation_testing.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c99d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first load the data from a URL\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/IHDP/csv/ihdp_npci_1.csv\", header = None)\n",
    "\n",
    "# here we are creating names for the columns\n",
    "col =  [\"treatment\", \"y_factual\", \"y_cfactual\", \"mu0\", \"mu1\" ,]\n",
    "for i in range(1,26):\n",
    "    col.append(\"x\"+str(i))\n",
    "data.columns = col\n",
    "\n",
    "# finally, we change the treatment column to a boolean and view the top of the dataframe\n",
    "data = data.astype({\"treatment\":'bool'}, copy=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ca06d",
   "metadata": {},
   "source": [
    "We can create the DoWhy causal model with the data and the common causes, and visualise the resulting causal graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making all 'x' variables common causes\n",
    "common_causes = []\n",
    "\n",
    "for i in range(1, 26):\n",
    "    common_causes += [\"x\"+str(i)]\n",
    "\n",
    "# creating and viewing the CausalModel\n",
    "ihdp_model = CausalModel(\n",
    "                data=data,\n",
    "                treatment='treatment',\n",
    "                outcome='y_factual',\n",
    "                common_causes=common_causes\n",
    "            )\n",
    "ihdp_model.view_model(layout=\"dot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3556e718",
   "metadata": {},
   "source": [
    "We can identify the causal effect from the causal graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff4a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the causal effect for the ihdp dataset\n",
    "ihdp_identified_estimand = ihdp_model.identify_effect(proceed_when_unidentifiable=True)\n",
    "print(ihdp_identified_estimand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a530c2",
   "metadata": {},
   "source": [
    "We can then calculate the causal estimate using propensity score weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3819180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ihdp_estimate = ihdp_model.estimate_effect(\n",
    "                    ihdp_identified_estimand,\n",
    "                    method_name=\"backdoor.propensity_score_stratification\"\n",
    "                )\n",
    "\n",
    "print(\"The Causal Estimate is \" + str(ihdp_estimate.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd48a3d",
   "metadata": {},
   "source": [
    "Finally, we test the validity of our estimate by replacing the treatment with a placebo. We see that there is now no effect from the treatment, increasing our confidence in our estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e5504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ihdp_refute_placebo_treatment = ihdp_model.refute_estimate(\n",
    "                                    ihdp_identified_estimand,\n",
    "                                    ihdp_estimate,\n",
    "                                    method_name=\"placebo_treatment_refuter\",\n",
    "                                    placebo_type=\"permute\"\n",
    "                                )\n",
    "\n",
    "print(ihdp_refute_placebo_treatment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_data_science_env",
   "language": "python",
   "name": "causal_data_science_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
